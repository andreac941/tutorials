{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreac941/tutorials/blob/main/ACTIVIDAD1/A1a_DL_TC5033_AD2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPaLdK_k_vKa"
      },
      "source": [
        "# TC 5033\n",
        "## Deep Learning\n",
        "## Fully Connected Deep Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGciPIz_vKb"
      },
      "source": [
        "#### Activity 1a: Implementing a Multilayer Fully Connected Network using Numpy\n",
        "#### Non-graded activity (0 points)\n",
        "\n",
        "- Objective\n",
        "\n",
        "The primary objective of this activity is to deepen your understanding of Fully Connected Networks by implementing a multilayer network using only Numpy. You  are  given  the follosing starter code that solves the MNIST dataset problem. Your task is to read, understand, and then apply this knowledge to solve classification problems on other datasets such as the Kaggle ASL dataset (Starter code will be provided separately for that activity).\n",
        "\n",
        "- Instructions\n",
        "\n",
        "    Read and Understand the following Code: The provided starter code outlines the architecture of a Fully Connected Network designed to classify MNIST images. Go through the code to understand how each function and class is used to implement the network.\n",
        "\n",
        "    Understand the Math: Make sure you understand the math operations implemented in the code, especially during the forward and backward passes. This will involve matrix multiplications, activation functions, loss computations, and backpropagation.\n",
        "    \n",
        "- Experiment\n",
        "    You are encouraged to play with the code, change any hyperparameters and train the model, you should be able to achieve over 95% accuracy on the test set without problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2P3NEcR1_vKc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mDMcxwa_vKd"
      },
      "source": [
        "### Import Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "71jcTS1B_vKd"
      },
      "outputs": [],
      "source": [
        "from get_images import get_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "qFi9hD3__vKd",
        "outputId": "125bd4ef-bb42-4ff2-a201-0344d3d89bea"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-2a5d96d06571>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmnist_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./mnist_raw/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#mnist_path = \"/content/mnist_raw.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/get_images.py\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(mnist_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'train-images'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/get_images.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(mnist_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './mnist_raw/'"
          ]
        }
      ],
      "source": [
        "# MNIST path\n",
        "mnist_path = './mnist_raw/'\n",
        "#mnist_path = \"/content/mnist_raw.zip\"\n",
        "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
        "\n",
        "x_train = x_train_num[:50000].reshape(50000, -1).astype(float)\n",
        "y_train = y_train_num[:50000].reshape(50000, 1)\n",
        "\n",
        "x_val = x_train_num[50000:].reshape(10000, -1).astype(float)\n",
        "y_val = y_train_num[50000:].reshape(10000, 1)\n",
        "\n",
        "x_test = x_test_num.copy().reshape(10000, -1).astype(float)\n",
        "y_test = y_test_num.copy().reshape(10000, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JFv_XHB_vKd"
      },
      "outputs": [],
      "source": [
        "x_train.mean(), x_train.std(), x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZYzOymS_vKd"
      },
      "outputs": [],
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5BSna51_vKe"
      },
      "outputs": [],
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYU9QlY3_vKe"
      },
      "outputs": [],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ETFg79_vKe"
      },
      "source": [
        "### Plot samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GeBAsrr_vKe"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o8RopQA_vKe"
      },
      "outputs": [],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
        "plot_number(x_test_num[rnd_idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTYldETg_vKe"
      },
      "source": [
        "### Equations\n",
        "\n",
        "\n",
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAnd3LdE_vKf"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMKEvffW_vKf"
      },
      "source": [
        "#### Creat Mini batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es5_xdrE_vKf"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(mb_size, x, y, shuffle = True):\n",
        "    '''\n",
        "    x  #muestras, 784\n",
        "    y #muestras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "    if shuffle:\n",
        "        idxs = np.arange(total_data)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s89haKdg_vKf"
      },
      "source": [
        "## Nuestra clase Linear, ReLU y Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peHaLGeP_vKf"
      },
      "outputs": [],
      "source": [
        "class np_tensor(np.ndarray): pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQV5nCaj_vKf"
      },
      "outputs": [],
      "source": [
        "a = np.array([0, 0])\n",
        "b = a.view(np_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv3OybxD_vKf"
      },
      "outputs": [],
      "source": [
        "type(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnnU_Ibm_vKg"
      },
      "outputs": [],
      "source": [
        "type(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ujx_soV_vKg"
      },
      "outputs": [],
      "source": [
        "a == b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTErl6KD_vKg"
      },
      "outputs": [],
      "source": [
        "a is b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUjcZmx2_vKg"
      },
      "source": [
        "###  Clase Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "maTxfn4u_vKg"
      },
      "outputs": [],
      "source": [
        "class Linear():\n",
        "    def __init__(self, input_size, output_size):\n",
        "        '''\n",
        "        Init parameters utilizando Kaiming He\n",
        "        '''\n",
        "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
        "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
        "    def __call__(self, X): # esta el foward de la clase lineal\n",
        "        Z = self.W @ X + self.b\n",
        "        return Z\n",
        "    def backward(self, X, Z):\n",
        "        X.grad = self.W.T @ Z.grad\n",
        "        self.W.grad = Z.grad @ X.T\n",
        "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpyorVQP_vKg"
      },
      "source": [
        "### Clase ReLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "9ZIS-qiy_vKg"
      },
      "outputs": [],
      "source": [
        "class ReLU():\n",
        "    def __call__(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "    def backward(self, Z, A):\n",
        "        Z.grad = A.grad.copy()\n",
        "        Z.grad[Z <= 0] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vtvEzMq_vKg"
      },
      "source": [
        "### Clase Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "aXwjDL_8_vKg"
      },
      "outputs": [],
      "source": [
        "class Sequential_layers():\n",
        "    def __init__(self, layers):\n",
        "        '''\n",
        "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
        "        '''\n",
        "        self.layers = layers\n",
        "        self.x = None\n",
        "        self.outputs = {}\n",
        "    def __call__(self, X):\n",
        "        self.x = X\n",
        "        self.outputs['l0'] = self.x\n",
        "        for i, layer in enumerate(self.layers, 1):\n",
        "            self.x = layer(self.x)\n",
        "            self.outputs['l'+str(i)]=self.x\n",
        "        return self.x\n",
        "    def backward(self):\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
        "    def update(self, learning_rate = 1e-3):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, ReLU): continue\n",
        "            layer.W = layer.W - learning_rate * layer.W.grad\n",
        "            layer.b = layer.b - learning_rate * layer.b.grad\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.__call__(X))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJZ7jz7h_vKh"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "bkA0ANmj_vKh"
      },
      "outputs": [],
      "source": [
        "def softmaxXEntropy(x, y):\n",
        "    batch_size = x.shape[1]\n",
        "    exp_scores = np.exp(x)\n",
        "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
        "    preds = probs.copy()\n",
        "    # Costo\n",
        "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
        "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
        "    # Calcular gradientes\n",
        "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
        "    x.grad = probs.copy()\n",
        "\n",
        "    return preds, cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHrtITXh_vKh"
      },
      "source": [
        "### Loop de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "fNTovgcO_vKh"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
        "    for epoch in range(epochs):\n",
        "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
        "            scores = model(x.T.view(np_tensor))\n",
        "            _, cost = softmaxXEntropy(scores, y)\n",
        "            model.backward()\n",
        "            model.update(learning_rate)\n",
        "        print(f'costo: {cost}, accuracy: {accuracy(x_val, y_val, mb_size)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [],
        "id": "rWcFvmpr_vKh"
      },
      "outputs": [],
      "source": [
        "def accuracy(x, y, mb_size):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
        "        pred = model(x.T.view(np_tensor))\n",
        "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
        "        total += pred.shape[1]\n",
        "    return correct/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GgN_tkH_vKh"
      },
      "outputs": [],
      "source": [
        "model = Sequential_layers([Linear(784, 200), ReLU(), Linear(200, 200), ReLU(), Linear(200, 10)])\n",
        "mb_size = 512\n",
        "learning_rate = 1e-4\n",
        "epochs = 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzCRJNJb_vKh"
      },
      "outputs": [],
      "source": [
        "train(model, epochs, mb_size, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC0jivHg_vKi"
      },
      "outputs": [],
      "source": [
        "print(accuracy(x_test, y_test, mb_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkOulDz1_vKi"
      },
      "outputs": [],
      "source": [
        "idx = np.random.randint(len(y_test))\n",
        "plot_number(x_test_num[idx])\n",
        "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
        "print(f'el valor predicho es: {pred}, el valor real es:{y_test[idx][0]}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}